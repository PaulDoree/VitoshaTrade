-> Замяна на сигмоидната функция с хиперболичен тангенс:

f(x) = (exp(2x)-1) / (exp(2x)+1)

-> На входа се подават мащабирани сигнали от стойностите във времевия ред. Вземат се определен брой стойности от отминалите периоди (примерно i на брой). 

-> На изхода се извеждат сигнали, които да се мащабират (примерно o на брой). Всичките стойности са прогнози в бъдещи периоди.

-> Дефиниция на мрежа:

NT = {N, W, A, T, ...}

N – вектор от невронни.

W – квадратна матрица на теглата.

A – квадратна матрица на активационните коефициенти (постигане на топология).

T – тестово множество.

-> Разполагане на невроните във вектора (масива), от нулев елемент към последен:

[output-> regular<-> input->]

-> При мрежи с рекурентна връзка ефект на атрактора. Изходните сигнали са приложими едва когато мрежата се установи в динамично равновесие.

-> Тренировъчните примери се променят защото времето напредва. Постъпват нови стълбове в графиката, а по-старите отпадат.

-> Изрисуване на топологията с позиции на невроните, според силата на теглата, връзките или двете (wij*aij). 

-> За всяка валута да се записва в базата данни минималната и максималната стойност (исторически известните), така че да ползват за мащабиране на входа и изхода в мрежата. 

-> Лимитиране на изхода в графичния потребителски интерфейс до видимите стойности в графиката. 

